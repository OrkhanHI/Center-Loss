{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Center Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the libraries\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import argparse\n",
    "import json \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from functools import partial \n",
    "#import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import copy\n",
    "import pdb \n",
    "from tqdm import tqdm\n",
    "from utils import * \n",
    "from torch.autograd import Variable\n",
    "from torch.autograd.function import Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing ResNet Source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In order to extract deep features ResNet base model output was changed to output deep features as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "\n",
    "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
    "           'resnet152']\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "}\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = conv1x1(inplanes, planes)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = conv3x3(planes, planes, stride)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = conv1x1(planes, planes * self.expansion)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        \n",
    "        # To save pre-final layer's features\n",
    "\n",
    "        feat = self.avgpool(self.layer4(x))\n",
    "        feat = feat.view(feat.size(0), -1)\n",
    "        x = self.fc(feat)\n",
    "        \n",
    "        return feat, x    #Extracted deep-features represented as 'feat'\n",
    "\n",
    "\n",
    "def resnet18(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data transformation\n",
    "def transfrom_data():\n",
    "    data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                            std=[0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                            std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    }\n",
    "\n",
    "    return data_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the data with transformation\n",
    "def load_data(batch_size, num_workers):\n",
    "    print(\"Start loading data\")\n",
    "    data_dir = '../'\n",
    "    image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), transfrom_data()[x]) for x in ['train', 'val']}\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=num_workers) \\\n",
    "                    for x in ['train', 'val']}\n",
    "    class_names = image_datasets['train'].classes\n",
    "    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "    print(\"Dataset sizes: Train {} Val {}\".format(dataset_sizes['train'], dataset_sizes['val']))\n",
    "    print(\"Number of classes: Train {} Val {}\".format(len(image_datasets['train'].classes), len(image_datasets['val'].classes)))\n",
    "\n",
    "    return dataloaders, class_names, dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the model, the FC layer of the model changed to 59 classes\n",
    "def load_model(class_names):\n",
    "    model = resnet18(pretrained=True)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, len(class_names)) #Changing from 1000 (ImageNet classes) to 59\n",
    "\n",
    "    model = torch.nn.DataParallel(model.cuda(), device_ids=[0])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CenterLoss(nn.Module):\n",
    "    \"\"\"Center loss.\n",
    "    \n",
    "    Reference:\n",
    "    Wen et al. A Discriminative Feature Learning Approach for Deep Face Recognition. ECCV 2016.\n",
    "    \n",
    "    Args:\n",
    "        num_classes (int): number of classes.\n",
    "        feat_dim (int): feature dimension.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=59, feat_dim=512, use_gpu=True):\n",
    "        super(CenterLoss, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.feat_dim = feat_dim\n",
    "        self.use_gpu = use_gpu\n",
    "\n",
    "        if self.use_gpu:\n",
    "            self.centers = nn.Parameter(torch.randn(self.num_classes, self.feat_dim).cuda())\n",
    "        else:\n",
    "            self.centers = nn.Parameter(torch.randn(self.num_classes, self.feat_dim))\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: feature matrix with shape (batch_size, feat_dim).\n",
    "            labels: ground truth labels with shape (batch_size).\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        distmat = torch.pow(x, 2).sum(dim=1, keepdim=True).expand(batch_size, self.num_classes) + \\\n",
    "                  torch.pow(self.centers, 2).sum(dim=1, keepdim=True).expand(self.num_classes, batch_size).t()\n",
    "        distmat.addmm_(1, -2, x, self.centers.t())\n",
    "\n",
    "        classes = torch.arange(self.num_classes).long()\n",
    "        if self.use_gpu: classes = classes.cuda()\n",
    "        labels = labels.unsqueeze(1).expand(batch_size, self.num_classes)\n",
    "        mask = labels.eq(classes.expand(batch_size, self.num_classes))\n",
    "\n",
    "        dist = distmat * mask.float()\n",
    "        loss = dist.clamp(min=1e-12, max=1e+12).sum() / batch_size\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_model(dataloaders, model, dataset_sizes, criterion, optimizer, num_epochs, save_dir, f):\n",
    "    since = time.time()\n",
    "    \n",
    "\n",
    "    best_val_top1_acc = 0.0\n",
    "    best_val_epoch = -1 \n",
    "    final_val_top5_acc = 0.0\n",
    "    #best_test_top1_acc = 0.0\n",
    "    #best_test_epoch = -1\n",
    "    #final_test_top5_acc = 0.0 \n",
    "\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            top1_running_corrects = 0\n",
    "            top5_running_corrects = 0\n",
    "\n",
    "            it = tqdm(range(len(dataloaders[phase])), desc=\"Epoch {}/{}, Split {}\".format(epoch, num_epochs - 1, phase), ncols=0)\n",
    "            data_iter = iter(dataloaders[phase])\n",
    "            for niter in it:\n",
    "                inputs, labels = data_iter.next()\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "                optimizer[0].zero_grad()\n",
    "                optimizer[1].zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    feats, outputs = model(inputs)\n",
    "                    \n",
    "                    loss = centerloss(feats, labels) * loss_weight + nllloss(outputs, labels)\n",
    "\n",
    "                    prec1, prec5 = accuracy(outputs, labels, topk=(1,5))\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "\n",
    "                        optimizer[0].step()\n",
    "                        optimizer[1].step()\n",
    "\n",
    "                training_loss = loss.item()\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                top1_running_corrects += prec1[0]\n",
    "                top5_running_corrects += prec5[0]\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            top1_epoch_acc = float(top1_running_corrects) / dataset_sizes[phase]\n",
    "            top5_epoch_acc = float(top5_running_corrects) / dataset_sizes[phase]\n",
    "            print('{} Epoch Loss: {:.6f} Epoch top1 Acc: {:.6f} Epoch top5 Acc: {:.6f}\\n'.format(phase, epoch_loss, top1_epoch_acc, top5_epoch_acc))\n",
    "            with open(epoch_trace_f_dir, \"a\") as f:\n",
    "                lr = optimizer[0].param_groups[0]['lr']\n",
    "                f.write(\"{},{},{},{:e},{:e},{:e}\\n\".format(epoch,phase,lr,epoch_loss,top1_epoch_acc,top5_epoch_acc))\n",
    "\n",
    "            if phase == 'val' and top1_epoch_acc > best_val_top1_acc:\n",
    "                print(\"Top1 val Acc improve from {:6f} --> {:6f}\".format(best_val_top1_acc, top1_epoch_acc))\n",
    "                best_val_top1_acc = top1_epoch_acc\n",
    "                final_val_top5_acc = top5_epoch_acc\n",
    "                best_val_epoch = epoch\n",
    "                save_f_dir = os.path.join(save_dir, \"best_val_model.ft\")\n",
    "                print(\"Saving best val model into {}...\".format(save_f_dir))\n",
    "                torch.save(model.state_dict(), save_f_dir)\n",
    "\n",
    "            #if phase == 'test' and top1_epoch_acc > best_test_top1_acc:\n",
    "                #print(\"Top1 test Acc improve from {:6f} --> {:6f}\".format(best_test_top1_acc, top1_epoch_acc))\n",
    "                #best_test_top1_acc = top1_epoch_acc\n",
    "                #final_test_top5_acc = top5_epoch_acc\n",
    "                #best_test_epoch = epoch \n",
    "                #save_f_dir = os.path.join(save_dir, \"best_test_model.ft\")\n",
    "                #print(\"Saving best test model into {}...\".format(save_f_dir))\n",
    "                #torch.save(model.state_dict(), save_f_dir)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best top1 val Acc: {:6f}'.format(best_val_top1_acc))\n",
    "    print('Final top5 val Acc: {:6f}'.format(final_val_top5_acc))\n",
    "    print('Best val model is saved at epoch # {}'.format(best_val_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading data\n",
      "Dataset sizes: Train 28236 Val 588\n",
      "Number of classes: Train 59 Val 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/29, Split train: 100% 883/883 [01:57<00:00,  7.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch Loss: 2.548705 Epoch top1 Acc: 0.620130 Epoch top5 Acc: 0.874593\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/29, Split val: 100% 19/19 [00:06<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Epoch Loss: 2.051797 Epoch top1 Acc: 0.741497 Epoch top5 Acc: 0.952381\n",
      "\n",
      "Top1 val Acc improve from 0.000000 --> 0.741497\n",
      "Saving best val model into ./outputs/best_val_model.ft...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/29, Split train: 100% 883/883 [01:56<00:00,  7.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch Loss: 1.946724 Epoch top1 Acc: 0.741996 Epoch top5 Acc: 0.940608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/29, Split val: 100% 19/19 [00:07<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Epoch Loss: 1.791669 Epoch top1 Acc: 0.792517 Epoch top5 Acc: 0.957483\n",
      "\n",
      "Top1 val Acc improve from 0.741497 --> 0.792517\n",
      "Saving best val model into ./outputs/best_val_model.ft...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/29, Split train: 100% 883/883 [01:55<00:00,  7.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch Loss: 1.748952 Epoch top1 Acc: 0.775818 Epoch top5 Acc: 0.954951\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/29, Split val: 100% 19/19 [00:06<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Epoch Loss: 1.669622 Epoch top1 Acc: 0.801020 Epoch top5 Acc: 0.960884\n",
      "\n",
      "Top1 val Acc improve from 0.792517 --> 0.801020\n",
      "Saving best val model into ./outputs/best_val_model.ft...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/29, Split train: 100% 883/883 [01:55<00:00,  7.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch Loss: 1.631634 Epoch top1 Acc: 0.796713 Epoch top5 Acc: 0.959166\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/29, Split val: 100% 19/19 [00:07<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Epoch Loss: 1.594183 Epoch top1 Acc: 0.811224 Epoch top5 Acc: 0.962585\n",
      "\n",
      "Top1 val Acc improve from 0.801020 --> 0.811224\n",
      "Saving best val model into ./outputs/best_val_model.ft...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/29, Split train: 100% 883/883 [01:55<00:00,  7.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch Loss: 1.549518 Epoch top1 Acc: 0.810030 Epoch top5 Acc: 0.962105\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/29, Split val: 100% 19/19 [00:07<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Epoch Loss: 1.512272 Epoch top1 Acc: 0.836735 Epoch top5 Acc: 0.962585\n",
      "\n",
      "Top1 val Acc improve from 0.811224 --> 0.836735\n",
      "Saving best val model into ./outputs/best_val_model.ft...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/29, Split train: 100% 883/883 [01:56<00:00,  7.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch Loss: 1.479354 Epoch top1 Acc: 0.820832 Epoch top5 Acc: 0.964620\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/29, Split val: 100% 19/19 [00:06<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Epoch Loss: 1.485426 Epoch top1 Acc: 0.828231 Epoch top5 Acc: 0.969388\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/29, Split train: 100% 883/883 [01:55<00:00,  7.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch Loss: 1.413147 Epoch top1 Acc: 0.834750 Epoch top5 Acc: 0.967205\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/29, Split val: 100% 19/19 [00:07<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Epoch Loss: 1.432132 Epoch top1 Acc: 0.826531 Epoch top5 Acc: 0.967687\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/29, Split train: 100% 883/883 [01:55<00:00,  7.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch Loss: 1.370012 Epoch top1 Acc: 0.839992 Epoch top5 Acc: 0.969826\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/29, Split val: 100% 19/19 [00:07<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Epoch Loss: 1.396901 Epoch top1 Acc: 0.835034 Epoch top5 Acc: 0.971088\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/29, Split train: 100% 883/883 [01:56<00:00,  7.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch Loss: 1.320041 Epoch top1 Acc: 0.850475 Epoch top5 Acc: 0.971880\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/29, Split val: 100% 19/19 [00:07<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Epoch Loss: 1.355436 Epoch top1 Acc: 0.848639 Epoch top5 Acc: 0.972789\n",
      "\n",
      "Top1 val Acc improve from 0.836735 --> 0.848639\n",
      "Saving best val model into ./outputs/best_val_model.ft...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/29, Split train: 100% 883/883 [01:57<00:00,  7.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch Loss: 1.282010 Epoch top1 Acc: 0.853697 Epoch top5 Acc: 0.972730\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/29, Split val: 100% 19/19 [00:07<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Epoch Loss: 1.331490 Epoch top1 Acc: 0.843537 Epoch top5 Acc: 0.974490\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/29, Split train: 100% 883/883 [01:56<00:00,  7.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch Loss: 1.250928 Epoch top1 Acc: 0.856779 Epoch top5 Acc: 0.973226\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/29, Split val: 100% 19/19 [00:06<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Epoch Loss: 1.321569 Epoch top1 Acc: 0.841837 Epoch top5 Acc: 0.974490\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/29, Split train: 100% 883/883 [01:56<00:00,  7.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch Loss: 1.228676 Epoch top1 Acc: 0.860426 Epoch top5 Acc: 0.973934\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/29, Split val: 100% 19/19 [00:07<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Epoch Loss: 1.297188 Epoch top1 Acc: 0.843537 Epoch top5 Acc: 0.976190\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/29, Split train: 100% 883/883 [01:55<00:00,  7.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch Loss: 1.188143 Epoch top1 Acc: 0.867651 Epoch top5 Acc: 0.976732\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/29, Split val: 100% 19/19 [00:06<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Epoch Loss: 1.276580 Epoch top1 Acc: 0.845238 Epoch top5 Acc: 0.977891\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/29, Split train: 100% 883/883 [01:56<00:00,  7.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch Loss: 1.169921 Epoch top1 Acc: 0.868430 Epoch top5 Acc: 0.976130\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/29, Split val: 100% 19/19 [00:06<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Epoch Loss: 1.257133 Epoch top1 Acc: 0.862245 Epoch top5 Acc: 0.976190\n",
      "\n",
      "Top1 val Acc improve from 0.848639 --> 0.862245\n",
      "Saving best val model into ./outputs/best_val_model.ft...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/29, Split train: 100% 883/883 [01:54<00:00,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch Loss: 1.142901 Epoch top1 Acc: 0.873636 Epoch top5 Acc: 0.976307\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/29, Split val: 100% 19/19 [00:06<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Epoch Loss: 1.232764 Epoch top1 Acc: 0.865646 Epoch top5 Acc: 0.976190\n",
      "\n",
      "Top1 val Acc improve from 0.862245 --> 0.865646\n",
      "Saving best val model into ./outputs/best_val_model.ft...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/29, Split train: 100% 883/883 [01:55<00:00,  7.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch Loss: 1.107198 Epoch top1 Acc: 0.880826 Epoch top5 Acc: 0.978928\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/29, Split val: 100% 19/19 [00:06<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Epoch Loss: 1.207959 Epoch top1 Acc: 0.857143 Epoch top5 Acc: 0.976190\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/29, Split train: 100% 883/883 [01:53<00:00,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch Loss: 1.089107 Epoch top1 Acc: 0.882915 Epoch top5 Acc: 0.978751\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/29, Split val: 100% 19/19 [00:07<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Epoch Loss: 1.190357 Epoch top1 Acc: 0.857143 Epoch top5 Acc: 0.974490\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/29, Split train: 100% 883/883 [01:54<00:00,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch Loss: 1.081267 Epoch top1 Acc: 0.880826 Epoch top5 Acc: 0.978113\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/29, Split val: 100% 19/19 [00:06<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Epoch Loss: 1.174122 Epoch top1 Acc: 0.867347 Epoch top5 Acc: 0.977891\n",
      "\n",
      "Top1 val Acc improve from 0.865646 --> 0.867347\n",
      "Saving best val model into ./outputs/best_val_model.ft...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/29, Split train: 100% 883/883 [01:55<00:00,  7.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch Loss: 1.054824 Epoch top1 Acc: 0.886209 Epoch top5 Acc: 0.978786\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/29, Split val: 100% 19/19 [00:06<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Epoch Loss: 1.172197 Epoch top1 Acc: 0.857143 Epoch top5 Acc: 0.977891\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/29, Split train: 100% 883/883 [01:57<00:00,  7.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch Loss: 1.046131 Epoch top1 Acc: 0.887874 Epoch top5 Acc: 0.979140\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/29, Split val: 100% 19/19 [00:06<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Epoch Loss: 1.166200 Epoch top1 Acc: 0.862245 Epoch top5 Acc: 0.979592\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/29, Split train: 100% 883/883 [01:56<00:00,  7.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch Loss: 1.025264 Epoch top1 Acc: 0.892655 Epoch top5 Acc: 0.980061\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/29, Split val: 100% 19/19 [00:07<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Epoch Loss: 1.140586 Epoch top1 Acc: 0.860544 Epoch top5 Acc: 0.979592\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/29, Split train: 100% 883/883 [01:57<00:00,  7.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch Loss: 1.001500 Epoch top1 Acc: 0.893398 Epoch top5 Acc: 0.980167\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/29, Split val: 100% 19/19 [00:06<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Epoch Loss: 1.132949 Epoch top1 Acc: 0.865646 Epoch top5 Acc: 0.979592\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/29, Split train: 100% 883/883 [01:56<00:00,  7.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch Loss: 0.990732 Epoch top1 Acc: 0.894709 Epoch top5 Acc: 0.981336\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/29, Split val: 100% 19/19 [00:06<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Epoch Loss: 1.123667 Epoch top1 Acc: 0.855442 Epoch top5 Acc: 0.979592\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/29, Split train: 100% 883/883 [01:54<00:00,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch Loss: 0.974285 Epoch top1 Acc: 0.896586 Epoch top5 Acc: 0.981832\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/29, Split val: 100% 19/19 [00:07<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Epoch Loss: 1.114754 Epoch top1 Acc: 0.865646 Epoch top5 Acc: 0.979592\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/29, Split train: 100% 883/883 [01:55<00:00,  7.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch Loss: 0.955825 Epoch top1 Acc: 0.900411 Epoch top5 Acc: 0.981300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/29, Split val: 100% 19/19 [00:07<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Epoch Loss: 1.108350 Epoch top1 Acc: 0.862245 Epoch top5 Acc: 0.979592\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/29, Split train: 100% 883/883 [01:56<00:00,  7.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch Loss: 0.943777 Epoch top1 Acc: 0.902571 Epoch top5 Acc: 0.982398\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/29, Split val: 100% 19/19 [00:07<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Epoch Loss: 1.111848 Epoch top1 Acc: 0.865646 Epoch top5 Acc: 0.979592\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/29, Split train: 100% 883/883 [01:56<00:00,  7.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch Loss: 0.935778 Epoch top1 Acc: 0.903350 Epoch top5 Acc: 0.981761\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/29, Split val: 100% 19/19 [00:07<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Epoch Loss: 1.113626 Epoch top1 Acc: 0.860544 Epoch top5 Acc: 0.979592\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/29, Split train: 100% 883/883 [01:55<00:00,  7.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch Loss: 0.927987 Epoch top1 Acc: 0.902677 Epoch top5 Acc: 0.982540\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/29, Split val: 100% 19/19 [00:06<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Epoch Loss: 1.106269 Epoch top1 Acc: 0.853741 Epoch top5 Acc: 0.977891\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/29, Split train: 100% 883/883 [01:55<00:00,  7.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch Loss: 0.917123 Epoch top1 Acc: 0.905404 Epoch top5 Acc: 0.981938\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/29, Split val: 100% 19/19 [00:06<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Epoch Loss: 1.093432 Epoch top1 Acc: 0.862245 Epoch top5 Acc: 0.979592\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/29, Split train: 100% 883/883 [01:56<00:00,  7.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch Loss: 0.908688 Epoch top1 Acc: 0.903811 Epoch top5 Acc: 0.982894\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/29, Split val: 100% 19/19 [00:07<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Epoch Loss: 1.083348 Epoch top1 Acc: 0.857143 Epoch top5 Acc: 0.979592\n",
      "\n",
      "\n",
      "Training complete in 61m 31s\n",
      "Best top1 val Acc: 0.867347\n",
      "Final top5 val Acc: 0.977891\n",
      "Best val model is saved at epoch # 17\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "\n",
    "    dataloaders, class_names, dataset_sizes = load_data(32, 12)\n",
    "    model= load_model(class_names)\n",
    "\n",
    "    #CrossEntropy\n",
    "    nllloss = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # CenterLoss\n",
    "    loss_weight = 0.001\n",
    "    centerloss = CenterLoss(num_classes=59, feat_dim=512, use_gpu=True)\n",
    "    \n",
    "    nllloss = nllloss.cuda()\n",
    "    centerloss = centerloss.cuda()\n",
    "    model = model.cuda()\n",
    "    \n",
    "    criterion = [nllloss, centerloss]\n",
    "    \n",
    "    # optimzer4nn\n",
    "    optimizer4nn = optim.Adagrad(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # optimzer4center\n",
    "    optimizer4center = optim.Adagrad(centerloss.parameters(), lr=0.001)\n",
    "    \n",
    "    optimizer = [optimizer4nn, optimizer4center]\n",
    "      \n",
    "    num_epochs = 30\n",
    "\n",
    "    save_dir = './outputs/'\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    epoch_trace_f_dir = os.path.join(save_dir, \"trace.csv\")\n",
    "    with open(epoch_trace_f_dir, \"w\") as f:\n",
    "        f.write(\"epoch,split,lr,loss,top1_acc,top5_acc\\n\")\n",
    "\n",
    "    train_model(dataloaders, model, dataset_sizes, criterion, optimizer, num_epochs, save_dir, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
